{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "69cca4ac-eee3-43e7-b30d-456b9f12a283",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: TensorFlow still sees GPUs: [PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]. CPU forcing might not be fully effective.\n",
      "tf.version.VERSION: 2.13.0\n",
      "Transformers version: 4.52.4\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2' # Suppress TF INFO/WARNING\n",
    "\n",
    "# Try to force CPU before TF initializes fully\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"-1\" # Should hide GPUs from TF\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "# After import, double-check and explicitly set visible devices to CPU only\n",
    "try:\n",
    "    tf.config.set_visible_devices([], 'GPU') # Tell TF to use no GPUs\n",
    "    physical_devices = tf.config.list_physical_devices('GPU')\n",
    "    if not physical_devices:\n",
    "        print(\"SUCCESS: TensorFlow is configured to use CPU only (no GPUs visible).\")\n",
    "    else:\n",
    "        print(f\"WARNING: TensorFlow still sees GPUs: {physical_devices}. CPU forcing might not be fully effective.\")\n",
    "except RuntimeError as e:\n",
    "    # This can happen if GPUs were already initialized or if there's a context issue\n",
    "    print(f\"RuntimeError during set_visible_devices: {e}. Will proceed assuming CPU if no GPU ops fail.\")\n",
    "except Exception as e_config:\n",
    "    print(f\"An unexpected error occurred during tf.config.set_visible_devices: {e_config}\")\n",
    "\n",
    "\n",
    "# Now, the rest of your imports\n",
    "import transformers\n",
    "from transformers import AutoTokenizer, TFAutoModelForSeq2SeqLM, pipeline\n",
    "import yake\n",
    "\n",
    "# Version checks (optional here, but good for confirmation)\n",
    "if hasattr(tf, 'keras') and hasattr(tf.keras, '__version__'):\n",
    "    print(f\"tf.keras.__version__: {tf.keras.__version__}\")\n",
    "if hasattr(tf, 'version') and hasattr(tf.version, 'VERSION'):\n",
    "    print(f\"tf.version.VERSION: {tf.version.VERSION}\")\n",
    "\n",
    "print(f\"Transformers version: {transformers.__version__}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0f41cddd-f860-4f9b-ba59-1be922eaff62",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All PyTorch model weights were used when initializing TFT5ForConditionalGeneration.\n",
      "\n",
      "All the weights of TFT5ForConditionalGeneration were initialized from the PyTorch model.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFT5ForConditionalGeneration for predictions without further training.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow Summarizer model 't5-small' loaded successfully.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All PyTorch model weights were used when initializing TFT5ForConditionalGeneration.\n",
      "\n",
      "All the weights of TFT5ForConditionalGeneration were initialized from the PyTorch model.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFT5ForConditionalGeneration for predictions without further training.\n",
      "Device set to use 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow Summarization pipeline for 't5-small' created successfully.\n"
     ]
    }
   ],
   "source": [
    "# --- Text Summarization (TensorFlow) ---\n",
    "\n",
    "summarizer_model_name = \"t5-small\" # T5 models work well with TensorFlow too\n",
    "\n",
    "# Load tokenizer (same as before) and TF model\n",
    "try:\n",
    "    summarizer_tokenizer = AutoTokenizer.from_pretrained(summarizer_model_name)\n",
    "    # Use TFAutoModelForSeq2SeqLM for TensorFlow-specific Keras model\n",
    "    summarizer_model_tf = TFAutoModelForSeq2SeqLM.from_pretrained(summarizer_model_name)\n",
    "    print(f\"TensorFlow Summarizer model '{summarizer_model_name}' loaded successfully.\")\n",
    "except Exception as e:\n",
    "    print(f\"Error loading TensorFlow summarizer model: {e}\")\n",
    "    summarizer_tokenizer = None\n",
    "    summarizer_model_tf = None\n",
    "\n",
    "# Using the Hugging Face pipeline with TensorFlow\n",
    "try:\n",
    "    # Specify framework=\"tf\" for TensorFlow pipeline\n",
    "    summarization_pipeline_tf = pipeline(\"summarization\", model=summarizer_model_name, tokenizer=summarizer_model_name, framework=\"tf\")\n",
    "    print(f\"TensorFlow Summarization pipeline for '{summarizer_model_name}' created successfully.\")\n",
    "except Exception as e:\n",
    "    print(f\"Error creating TensorFlow summarization pipeline: {e}\")\n",
    "    summarization_pipeline_tf = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d0ac8417-03c1-41e5-ba1d-3702acc4557f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Summary (Direct TF Method) ---\n",
      "machine learning enables systems to learn from data and make predictions or decisions without being explicitly programmed. deep learning, a subset of AI, enables systems to learn from data and make predictions or decisions without being explicitly programmed.\n"
     ]
    }
   ],
   "source": [
    "def summarize_text_direct_tf(text, model, tokenizer, max_length=150, min_length=30, num_beams=4):\n",
    "    \"\"\"\n",
    "    Summarizes text using a pre-trained TensorFlow Seq2Seq model and tokenizer directly.\n",
    "    \"\"\"\n",
    "    if model is None or tokenizer is None:\n",
    "        return \"Summarizer TF model not loaded.\"\n",
    "\n",
    "    if \"t5\" in model.name.lower(): # Accessing model name might be slightly different for TF models\n",
    "         preprocess_text = \"summarize: \" + text.strip().replace(\"\\n\", \" \")\n",
    "    else:\n",
    "         preprocess_text = text.strip().replace(\"\\n\", \" \")\n",
    "\n",
    "    # Tokenize for TensorFlow: ensure return_tensors=\"tf\"\n",
    "    inputs = tokenizer(preprocess_text, return_tensors=\"tf\", max_length=1024, truncation=True)\n",
    "\n",
    "    # Generate summary using TensorFlow model's generate method\n",
    "    summary_ids = model.generate(\n",
    "        inputs.input_ids, # Pass input_ids tensor\n",
    "        max_length=max_length,\n",
    "        min_length=min_length,\n",
    "        num_beams=num_beams,\n",
    "        early_stopping=True\n",
    "    )\n",
    "\n",
    "    summary = tokenizer.decode(summary_ids[0], skip_special_tokens=True)\n",
    "    return summary\n",
    "\n",
    "# Example Usage (Direct TF Method)\n",
    "sample_text_long = \"\"\"\n",
    "Artificial intelligence (AI) is rapidly transforming various industries, from healthcare to finance and entertainment.\n",
    "Machine learning, a subset of AI, enables systems to learn from data and make predictions or decisions without being explicitly programmed.\n",
    "Deep learning, a further specialization, utilizes neural networks with many layers to analyze complex patterns in large datasets.\n",
    "Natural Language Processing (NLP) allows computers to understand, interpret, and generate human language, powering applications like chatbots and machine translation.\n",
    "Computer vision, another AI field, focuses on enabling machines to interpret and understand visual information from the world, such as images and videos.\n",
    "The ethical implications of AI, including bias in algorithms and job displacement, are critical areas of ongoing discussion and research.\n",
    "As AI technology continues to advance, its integration into daily life is expected to grow, offering both opportunities and challenges.\n",
    "Developing robust and responsible AI systems is paramount for harnessing its full potential while mitigating risks.\n",
    "Many companies are investing heavily in AI research and development to gain a competitive edge.\n",
    "\"\"\"\n",
    "\n",
    "if summarizer_model_tf and summarizer_tokenizer:\n",
    "    summary1_tf = summarize_text_direct_tf(sample_text_long, summarizer_model_tf, summarizer_tokenizer)\n",
    "    print(\"--- Summary (Direct TF Method) ---\")\n",
    "    print(summary1_tf)\n",
    "else:\n",
    "    print(\"Skipping direct TF summarization as model/tokenizer failed to load.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0ffeed09-a5b1-4c95-a40e-8eeef190f471",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Summary (TF Pipeline Method) ---\n",
      "machine learning enables systems to learn from data and make predictions or decisions without being explicitly programmed . natural language processing (NLP) allows computers to understand, interpret, and generate human language, powering applications like chatbots and machine translation .\n"
     ]
    }
   ],
   "source": [
    "def summarize_text_pipeline_tf(text, pipeline_instance, max_length=150, min_length=30):\n",
    "    \"\"\"\n",
    "    Summarizes text using the Hugging Face TensorFlow summarization pipeline.\n",
    "    \"\"\"\n",
    "    if pipeline_instance is None:\n",
    "        return \"Summarization TF pipeline not loaded.\"\n",
    "    \n",
    "    try:\n",
    "        result = pipeline_instance(text, max_length=max_length, min_length=min_length, do_sample=False)\n",
    "        return result[0]['summary_text']\n",
    "    except Exception as e:\n",
    "        return f\"Error during TF pipeline summarization: {e}\"\n",
    "\n",
    "# Example Usage (TF Pipeline Method)\n",
    "if summarization_pipeline_tf:\n",
    "    summary2_tf = summarize_text_pipeline_tf(sample_text_long, summarization_pipeline_tf)\n",
    "    print(\"\\n--- Summary (TF Pipeline Method) ---\")\n",
    "    print(summary2_tf)\n",
    "else:\n",
    "    print(\"Skipping TF pipeline summarization as pipeline failed to create.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "60469c33-9348-4d9e-8a6d-057b79efb6dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Extracted Tags (YAKE!) ---\n",
      "['Artificial intelligence', 'transforming various industries', 'finance and entertainment', 'rapidly transforming', 'healthcare to finance', 'Natural Language Processing', 'Language Processing', 'Machine learning', 'Deep learning', 'Artificial']\n"
     ]
    }
   ],
   "source": [
    "# --- Keyword/Tag Extraction (using YAKE!) ---\n",
    "\n",
    "# YAKE! parameters\n",
    "language = \"en\"\n",
    "max_ngram_size = 3\n",
    "deduplication_threshold = 0.9\n",
    "num_of_keywords = 10\n",
    "\n",
    "kw_extractor = yake.KeywordExtractor(lan=language, \n",
    "                                     n=max_ngram_size, \n",
    "                                     dedupLim=deduplication_threshold, \n",
    "                                     top=num_of_keywords, \n",
    "                                     features=None)\n",
    "\n",
    "def extract_tags_yake(text, extractor):\n",
    "    if extractor is None:\n",
    "        return [\"YAKE! extractor not initialized.\"]\n",
    "    try:\n",
    "        keywords_with_scores = extractor.extract_keywords(text)\n",
    "        keywords = [kw[0] for kw in keywords_with_scores]\n",
    "        return keywords\n",
    "    except Exception as e:\n",
    "        return [f\"Error during YAKE! keyword extraction: {e}\"]\n",
    "\n",
    "# Example Usage (YAKE!)\n",
    "tags_tf = extract_tags_yake(sample_text_long, kw_extractor) # Renamed variable for clarity\n",
    "print(\"\\n--- Extracted Tags (YAKE!) ---\")\n",
    "print(tags_tf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e2f8604c-d78b-4fb1-85dd-422ff8609d8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Combined Analysis (TF) ---\n",
      "Original Text Length (words): 167\n",
      "Summary: machine learning enables systems to learn from data and make predictions or decisions without being explicitly programmed . natural language processing (NLP) allows computers to understand, interpret, and generate human language, powering applications like chatbots and machine translation .\n",
      "Summary Length (words): 39\n",
      "Tags: ['Artificial intelligence', 'transforming various industries', 'finance and entertainment', 'rapidly transforming', 'healthcare to finance', 'Natural Language Processing', 'Language Processing', 'Machine learning', 'Deep learning', 'Artificial']\n"
     ]
    }
   ],
   "source": [
    "def summarize_and_tag_tf(text, summarizer_tf_pipe, tag_extractor):\n",
    "    summary = \"Could not summarize.\"\n",
    "    tags_list = [\"Could not extract tags.\"]\n",
    "\n",
    "    if summarizer_tf_pipe:\n",
    "        summary = summarize_text_pipeline_tf(text, summarizer_tf_pipe) # Use TF pipeline function\n",
    "    \n",
    "    if tag_extractor:\n",
    "        tags_list = extract_tags_yake(text, tag_extractor)\n",
    "        \n",
    "    return {\n",
    "        \"original_text_length\": len(text.split()),\n",
    "        \"summary\": summary,\n",
    "        \"summary_length\": len(summary.split()),\n",
    "        \"tags\": tags_list\n",
    "    }\n",
    "\n",
    "# Example of combined function\n",
    "if summarization_pipeline_tf and kw_extractor:\n",
    "    analysis_result_tf = summarize_and_tag_tf(sample_text_long, summarization_pipeline_tf, kw_extractor)\n",
    "    print(\"\\n--- Combined Analysis (TF) ---\")\n",
    "    print(f\"Original Text Length (words): {analysis_result_tf['original_text_length']}\")\n",
    "    print(f\"Summary: {analysis_result_tf['summary']}\")\n",
    "    print(f\"Summary Length (words): {analysis_result_tf['summary_length']}\")\n",
    "    print(f\"Tags: {analysis_result_tf['tags']}\")\n",
    "else:\n",
    "    print(\"Skipping combined TF analysis due to issues with pipeline or extractor.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70a08536-1c7a-40cb-b520-7d997bd667f0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10 ARM64 (Content Analyzer)",
   "language": "python",
   "name": "content_analyzer_arm64"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
